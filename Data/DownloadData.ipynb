{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "658294a9",
   "metadata": {},
   "source": [
    "# Download Data \n",
    "This is the Data needed for the Jupyter Notebooks in the folder DataAnalysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "68c48306",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import gc\n",
    "import hdf5plugin\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import requests\n",
    "import scanpy as sc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e221d112",
   "metadata": {},
   "source": [
    "General Settings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1da8a25a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory:\n",
    "data_dir = Path(\".\") / \"Data\"\n",
    "data_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# Download function:\n",
    "def download_file(url, output_dir, use_cache=True):\n",
    "    filename = output_dir / os.path.basename(url)\n",
    "    \n",
    "    if use_cache and filename.exists():\n",
    "        print(f\"File already exists, skipping: {filename}\")\n",
    "        return filename\n",
    "\n",
    "    response = requests.get(url, stream=True)\n",
    "    response.raise_for_status()\n",
    "    \n",
    "    with open(filename, \"wb\") as file:\n",
    "        for chunk in response.iter_content(chunk_size=8192):\n",
    "            file.write(chunk)\n",
    "    \n",
    "    print(f\"Downloaded: {filename}\")\n",
    "    return filename"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12ec2a2b",
   "metadata": {},
   "source": [
    "## Hepatocytes Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "59778c52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists, skipping: Data/GSE84498%5Fexperimental%5Fdesign.txt.gz\n",
      "File already exists, skipping: Data/GSE84498%5Fumitab.txt.gz\n"
     ]
    }
   ],
   "source": [
    "# Download data files:\n",
    "file_urls = [\n",
    "    \"https://ftp.ncbi.nlm.nih.gov/geo/series/GSE84nnn/GSE84498/suppl/GSE84498%5Fexperimental%5Fdesign.txt.gz\",\n",
    "    \"https://ftp.ncbi.nlm.nih.gov/geo/series/GSE84nnn/GSE84498/suppl/GSE84498%5Fumitab.txt.gz\"\n",
    "    ]\n",
    "for url in file_urls:\n",
    "    download_file(url=url, output_dir=data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "65237801",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the AnnData object:\n",
    "obs = (pd.read_csv(data_dir / os.path.basename(file_urls[0]), sep=\"\\t\")\n",
    "       .set_index(\"well\"))\n",
    "count_df = (pd.read_csv(data_dir / os.path.basename(file_urls[1]), sep=\"\\t\")\n",
    "            .set_index(\"gene\").T\n",
    "            .loc[obs.index, :])\n",
    "adata_hep = sc.AnnData(\n",
    "    X = count_df.values.astype(np.float32),\n",
    "    obs = obs, \n",
    "    var = pd.DataFrame(index=[c.split(\";\")[0] for c in count_df.columns])\n",
    ")\n",
    "adata_hep = adata_hep[:, adata_hep.X.sum(axis=0) >= 20].copy()\n",
    "# remove batches of different cells (probably non-hepatocytes)\n",
    "adata_hep = adata_hep[~adata_hep.obs[\"batch\"].isin([\"AB630\", \"AB631\"])].copy()\n",
    "adata_hep.write_h5ad( data_dir / \"adata_hep.h5ad\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "016ba9d5",
   "metadata": {},
   "source": [
    "## Non-classical Monocytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "edaf5646",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists, skipping: Data/4532eea4-24b7-461a-93f5-fe437ee96f0a.h5ad\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PosixPath('Data/4532eea4-24b7-461a-93f5-fe437ee96f0a.h5ad')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# File URL to download\n",
    "url = \"https://datasets.cellxgene.cziscience.com/4532eea4-24b7-461a-93f5-fe437ee96f0a.h5ad\"\n",
    "\n",
    "# Download the file\n",
    "download_file(url=url, output_dir=data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f4f5f592",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hd/hd_hd/hd_fb235/.conda/envs/partipy/lib/python3.11/site-packages/anndata/_core/anndata.py:750: UserWarning: \n",
      "AnnData expects .var.index to contain strings, but got values like:\n",
      "    ['MIR1302-2HG', 'FAM138A', 'OR4F5', 'ENSG00000238009.6', 'ENSG00000239945.1']\n",
      "\n",
      "    Inferred to be: categorical\n",
      "\n",
      "  value_idx = self._prep_dim_index(value.index, attr)\n"
     ]
    }
   ],
   "source": [
    "# Save the AnnData object:\n",
    "adata_ncM = sc.read_h5ad(data_dir / \"4532eea4-24b7-461a-93f5-fe437ee96f0a.h5ad\")\n",
    "adata_ncM.obs[\"Status\"] = adata_ncM.obs[\"disease_state\"].map({\n",
    "    \"managed\": \"Managed\",\n",
    "    \"na\": \"Healthy\",\n",
    "    \"flare\": \"Flare\",\n",
    "    \"treated\": \"Treated\"\n",
    "})\n",
    "adata_ncM = adata_ncM[adata_ncM.obs[\"author_cell_type\"]==\"ncM\", :].copy() # only consider non-classical monocytes\n",
    "adata_ncM = adata_ncM[adata_ncM.obs[\"Status\"] != \"Treated\", :].copy() # remove samples with \"treated\" status\n",
    "# remove columns we don\"t need\n",
    "adata_ncM.obs.drop(columns=[\"mapped_reference_annotation\", \"cell_type_ontology_term_id\", \"is_primary_data\", \n",
    "                        \"cell_state\", \"tissue_ontology_term_id\", \"development_stage_ontology_term_id\", \n",
    "                        \"tissue\", \"organism\", \"tissue_type\", \"suspension_type\", \"organism_ontology_term_id\",\n",
    "                        \"assay_ontology_term_id\", \"suspension_enriched_cell_types\", \"suspension_uuid\",\n",
    "                        \"self_reported_ethnicity_ontology_term_id\", \"disease_ontology_term_id\",\n",
    "                        \"sex_ontology_term_id\"], \n",
    "                        inplace=True)\n",
    "# create new index\n",
    "adata_ncM.obs.index = [s.split(\"-\")[0] + \"-\" + str(len(s.split(\"-\"))) + \"-\" + str(donor_id) \n",
    "                   for s, donor_id in zip(adata_ncM.obs.index, adata_ncM.obs[\"donor_id\"].to_list())]\n",
    "# remove obsm we don't need\n",
    "del adata_ncM.obsm[\"X_pca\"], adata_ncM.obsm[\"X_umap\"], adata_ncM.uns\n",
    "gc.collect()\n",
    "\n",
    "# use the raw counts\n",
    "adata_ncM.X = adata_ncM.raw.X\n",
    "\n",
    "# use gene symbols instead of ensembl IDs\n",
    "assert len(adata_ncM.var[\"feature_name\"]) == len(adata_ncM.var[\"feature_name\"].unique())\n",
    "adata_ncM.var = adata_ncM.var.set_index(\"feature_name\")\n",
    "\n",
    "adata_ncM.write_h5ad( data_dir / \"adata_ncM.h5ad\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "partipy",
   "language": "python",
   "name": "partipy"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
